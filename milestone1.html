o<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="3400 : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Milestone 1</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://sanskritijoshi1441.github.io/3400/">View on GitHub</a>

          <h1 id="project_title">Milestone1</h1>
          <h2 id="project_tagline"></h2>
          <a href = "index.html">Home</a>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
     
<h3> Goals</h3>
<p></p>
&#8226; To have the robot adjust as it traverses a straight line.<p></p>
&#8226; To have the robot traverse the grid in a figure eight.<p> </p>

<h3> Line Detection </h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/d6kF6FJvlLk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
<p> To ensure our robot could travel in a straight line, we added QRE113 IR line sensors. Before proceeding to writing the code, we tested the sensors and observed the values they outputted depending on the surfaces they covered. Using this method, we determined the threshold value we wanted to use to differentiate between black and white surfaces.</p>
        <p> The sensors were then placed on the front of the robot, while very close to the ground to optimize the accurary of the sensor readings. </p>
        <img src = "milestone_img/IMG_2677.JPG" alt="hi" class="inline">  
        <p> We separated the sensors by a distance slightly more than the width of the tape so that they could straddle the white lines that we wanted the robot to follow. This way, the sensors could detect either the white lines' reflected intensity or the black mazeâ€™s intensity. We coded the robot to continue its forward trajectories as long as both sensors detected black (assuming the robot was placed directly above the white line to begin with). As soon as one detected white light, the robot would briefly change the rotation of the servos to adjust its course.</p>
<p> The code for these adjustments are shown in the image below: </p>
<img src = "milestone_img/sensor_moves_works.jpg" alt="hi" class="inline">
        
<p> Our final conditions for the robot to follow the line were as follows:</p>
     &#8226; If both sensors detect white or both detect black, we programmed the robot to go straight. <p></p>
        &#8226; If the left sensor detects black and the right white, we had the robot adjust right until both detect the same color again.<p></p>
        &#8226; If the left sensor detects white and the right black, we had the robot adjust right until both detect the same color again.<p></p>

   
<h3> Figure Eight </h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/G1xp0DfKNp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
<p> In order to make the robot turn, we needed to have the robot both detect an intersection and start and stop the turn at precise moments. Our initial method is as follows:</p>
        
        &#8226; Once both sensors detected white (an intersection), we had the robot begin turning in the appropriate direction<p></p>
        &#8226; While turning, we wanted the robot to detect when the outside sensor reached black, and then white again. This would signal the end of the turn, and the robot would return to moving straight. By 'outside sensor' here, we are referring to the sensor on the side opposite the turn direction, because its detection of the new white line signaled the completion of the turn. <p></p>
        <p> We implemented these ideas in the following code:</p>
        <img src = "milestone_img/figure_eight_works.jpg" alt="hi" class="inline">                                                                    
                                                                                 
        <p>Our team encountered many issues before we were successful. For one, the robot would often overshoot the intersection, causing it to miss the line when it turned and run off the track. This issue was resolved by adding a delay to the intersection detection portion of the code, which allowed the robot to recognize that it was time to turn. Another issue we faced was that when the robot turned immediately upon detection, it would end up offset relative to the new line it was supposed to follow. This occurred because our sensors were in front of the robot, and to stay aligned with the new line, we needed the robot's center of rotation to stay directly above the intersection. To resolve this issue, we added a short time delay between detecting an intersection and turning to account for the distance between the sensors and the robot's turning axis. This allowed for the sensors to accurately detect the next straight line the robot needed to traverse. </p>

     




